# aind-disrnn-dispatcher

The dispatcher capsule in the AIND-disRNN MLOps stack

<img width="1411" height="883" alt="image" src="https://github.com/user-attachments/assets/0fa633e2-d91e-4320-901d-054118cd5192" />


# Usage

This capsule uses Hydra to compose configurations from the files under
`code/config/`. You can invoke it directly with Python or via the CO's input arguments
(which passes the arguments via the "run" file).

Examples (direct Python invocation)
1. Default single run with the default parameters (data=mice, model=disrnn)
   
    Uses the defaults declared in `config/config.yaml`:
    ```bash
    python code/run_capsule.py
    ```
    Explicit form:
    ```bash
    python code/run_capsule.py data=mice model=disrnn
    ```

    Here is the output

    ```json
    {
        "data": {
            "source": "mice",
            "subject_ids": [
                774212
            ],
            "multisubject": false,
            "ignore_policy": "exclude",
            "features": {
                "animal_response": "prev choice",
                "rewarded": "prev reward"
            }
        },
        "model": {
            "type": "disrnn",
            "architecture": {
                "latent_size": 5,
                "update_net_n_units_per_layer": 16,
                "update_net_n_layers": 8,
                "choice_net_n_units_per_layer": 4,
                "choice_net_n_layers": 1,
                "activation": "leaky_relu"
            },
            "penalties": {
                "beta": 0.01,
                "latent_penalty": 0.01,
                "choice_net_latent_penalty": 0.01,
                "update_net_obs_penalty": 0.01,
                "update_net_latent_penalty": 0.01
            },
            "training": {
                "n_steps": 3000,
                "n_warmup_steps": 1000,
                "lr": 0.001,
                "eval_every_n": 100,
                "loss": "penalized_categorical",
                "loss_param": 1.0
            }
        },
        "job_id": 0,
        "seed": 42,
        "wandb": {
            "entity": "AIND-disRNN"
        }
    }
    ```

3. Synthetic data generated by an RL agent performing an uncoupled_block task

    Override the top-level data source and model; specify nested synthetic groups:
    ```bash
    python code/run_capsule.py data=synthetic data.synthetic.agent=rl data.synthetic.task=uncoupled_block model=baseline_rl
    ```

5. Hydra multirun sweep over model penalties beta and training learning rate
   
    Use `-m` (or `--multirun`) to launch a Cartesian product of overrides:
    ```bash
    python code/run_capsule.py -m model.penalties.beta=0.0001,0.001,0.01 model.training.lr=0.0001,0.001
    ```
    Results will be placed under `results/` using Hydra-generated job IDs.


## Additional notes

* All composed configurations are serialized to JSON at `.hydra/config.json` inside the run directory.
* To call programmatically from Python:
  ```python
  from run_capsule import generate_jobs_with_args
  generate_jobs_with_args(["data=mice", "model=disrnn", "job_id=42"])
  ```

# Usage in Code Ocean
- Enter the whole override string in the app panel and hit "Run"<br>
  <img width="400" alt="image" src="https://github.com/user-attachments/assets/92ee7654-802b-49f4-8ed8-9e87bc879cd8" />
- You'll see all generated jobs like this<br>
  <img width="400" alt="image" src="https://github.com/user-attachments/assets/15627c06-784a-4cb7-a4b2-903a2fdec52b" />

      
